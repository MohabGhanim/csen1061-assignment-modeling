Loading Required Packages:
```{r loading_required_packages}
rm(list = ls())
library(dplyr)
library(tidyr)
library(caret)
library(RWeka)
library(kernlab)
library(ROCR)
library(klaR)
library(MASS)
library(adabag)
```

```{r defining_functions}
get.f1.measure <- function(model, weka_matrix = F){
  if(weka_matrix == T){
    confusion_matrix <- t(model$confusionMatrix)
  }else{
    confusion_matrix <- as.matrix(confusionMatrix(model)$table)
  }
  tp <- confusion_matrix[1,1]
  fn <- confusion_matrix[2,1]
  fp <- confusion_matrix[1,2]
  tn <- confusion_matrix[2,2]
  precision <- tp/(tp+fp)
  recall <- tp/(tp+fn)
  f1 <- 2*(precision*recall)/(precision+recall)
  return(f1)
}

c.train <- function(.data, .method, .trControl ){
  set.seed(1234)
  mdl <- train(label~.,
                 data = .data,
                 method=.method,
                 preProc=c("center","scale"),
                 trControl=.trControl)
}

ctr <- trainControl(method="repeatedcv",
                    repeats = 5, 
                    classProbs = TRUE,
                    summaryFunction = twoClassSummary)

ctr2 <- trainControl(method="repeatedcv",
                    repeats = 10)


```
##1
Reading Data and renaming label
```{r reading_data}
sonar <- read.csv("sonar.csv", header = F)
sonar <- sonar[sample(nrow(sonar)),]
names(sonar)[61] <- "label"
```

##2
Training C4.5 Classifier usnig J48 from Weka, without tuning paramters

Note: All the cross validation functions used implement stratified cross validation scheme, where the variability in the data across the labels, is maintained in the created folds
```{r J48_1}
#Using J48 function
  mdl.tst1 <- J48(label ~ ., data = sonar)
  plot(mdl.tst1)
  summary(mdl.tst1)
```

Traingin C4.5 Classifier using J48 from Weka, with limiting the number of instances per leaf to 1 instead of 2 (the default for weka)
```{r J48_2}
#Settings the minimum number of instances per leaf makes the model overly fitting
  mdl.tst2 <- J48(label ~ ., data = sonar, control =Weka_control(M=1))
  plot(mdl.tst2)
  summary(mdl.tst2)
```


Evaluaitng the created models
```{r evaluating_j48_1_and_2}
p1 <- predict(mdl.tst1, sonar)
t1 <- table(p1,sonar$label)
confusionMatrix(t1)

p2 <- predict(mdl.tst2,sonar)
t2 <- table(p2,sonar$label)
confusionMatrix(t2)
#Both tables show the same results obtained from the training process because we are training and testing against the same dataset
```

Now, we will try evaluating the model using cross validation, we will use the cross validation utitlity from the caret package instead of weka package, since it has the option to repear the process of cross validation using differnet folds, and is more descriptive in terms of performances metrics such as sensitivity, specificity, pos pred value, and neg pred value
```{r cross_validation}
mdl.c45 <- c.train(sonar, "J48",ctr)
get.f1.measure(mdl.c45)
```


Trying SVM with radial basis function kernel using the same adaptor we used for C4.5
```{r svm}
mdl.svm <- c.train(sonar, "svmRadial", ctr)
get.f1.measure(mdl.svm)
```

Trying a simple Naive Bayes Classifier
```{r naive_bayes}
mdl.nb <- c.train(sonar, "nb", ctr)
get.f1.measure(mdl.nb)
```

Trying a regularized Random Forest
```{r random_forest}
mdl.rf <- c.train(sonar, "rf", ctr)
get.f1.measure(mdl.rf)
```

Trying a simple neural network
```{r nnet,results="hide",message=FALSE}
mdl.nnet <- c.train(sonar, "nnet", ctr)
```

```{r}
print(get.f1.measure(mdl.nnet))  
```

Trying a neural network with dimensionality reduction
```{r pcaNNet,results="hide",message=FALSE}
mdl.nnetPCA <- c.train(sonar, "pcaNNet", ctr)
```

```{r}
print(get.f1.measure(mdl.nnetPCA))
```

##3
Bagging
```{r bagging}
bg <- Bagging(label~., sonar, control = Weka_control(W="J48"))
ev.bg <- evaluate_Weka_classifier(bg,numFolds = 10)
get.f1.measure(ev.bg, weka_matrix = T)
```
Boosting
```{r boositng}
bst <- AdaBoostM1(label~., sonar, control = Weka_control(W="J48"))
ev.bst <- evaluate_Weka_classifier(bst, numFolds= 10)
get.f1.measure(ev.bst, weka_matrix = T)
```

##4
Loading Hepatitis Package
```{r loading_hepatits}
hep <- read.csv("hepatitis.csv", header = F, na.strings = "?")
hep <- hep[sample(nrow(hep)),]
names(hep)[1] <- "label"
hep$label <- factor(hep$label)
```

Loading and Merging spect
```{r loading_spect}
spect.1 <- read.csv("spect_train.csv", header=F)
spect.2 <- read.csv("spect_test.csv", header=F)
spect <- rbind(spect.1,spect.2)
spect <- spect[sample(nrow(spect)),]
names(spect)[1] <- "label"
spect$label <- factor(spect$label)
```

Loading pima
```{r loading_pima}
pima <- read.csv("pima.csv", header = F)
pima <- pima[sample(nrow(pima)),]
names(pima)[9] = "label"
pima$label <- factor(pima$label)
```


Creating Matrix
```{r creating_matrix}
#algorithms <- c("J48", "svmRadial", "nb", "rf", "nnet", "pcaNNet", "AdaBoost.M1")
datasets <- list(hep,pima,spect)
res.mat <- matrix(nrow = length(datasets), ncol=length(algorithms))
colnames(res.mat) <- algorithms
rownames(res.mat) <- c("hep","pima","spect")
for(d in 1:length(datasets)){
  dataset <- datasets[[d]]
  a <- 1
  for(algorithm in algorithms){
    mdl <- c.train(dataset, algorithm,ctr2)
    f1 <- get.f1.measure(mdl)
    res.mat[d,a] = f1
    a <- a+1
  }
}
```